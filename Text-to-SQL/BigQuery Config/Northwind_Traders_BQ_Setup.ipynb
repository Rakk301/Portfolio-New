{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBIxqlXhRKMy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pandas\n",
        "!pip install --upgrade google-cloud-bigquery\n",
        "!pip install --upgrade google-cloud-storage\n",
        "!pip install sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate Google Account\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "B_bXrPAvRMuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Set your Google Cloud Project ID here\n",
        "project_id = 'Text-SQL-Project'\n",
        "client = bigquery.Client(project=project_id)\n"
      ],
      "metadata": {
        "id": "l3MIpcmSYojR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Initialize Cloud Storage client\n",
        "storage_client = storage.Client(project=project_id)\n",
        "\n",
        "# Create a new bucket (if you don't already have one)\n",
        "bucket_name = 'northwind_dataset_bucket'  # Change this to a unique name\n",
        "bucket = storage_client.create_bucket(bucket_name)\n",
        "\n",
        "print(f\"Bucket {bucket_name} created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMYbgX_mYx3U",
        "outputId": "a33164a7-c8fb-4281-b1ed-869da44829cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bucket northwind_dataset_bucket created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXV0XjhTaV3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('northwind.db')\n",
        "\n",
        "# Get the list of all tables in the database\n",
        "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
        "tables = pd.read_sql_query(tables_query, conn)\n",
        "\n",
        "# Iterate over each table and export it as a CSV\n",
        "for table in tables['name']:\n",
        "    # Wrap the table name in square brackets to handle table names with spaces\n",
        "    table_name_escaped = f'[{table}]'\n",
        "\n",
        "    try:\n",
        "        # Read each table into a pandas DataFrame\n",
        "        df = pd.read_sql_query(f\"SELECT * FROM {table_name_escaped}\", conn)\n",
        "\n",
        "        # Export the table to a CSV file\n",
        "        df.to_csv(f'{table}.csv', index=False)\n",
        "        print(f\"Exported {table} to {table}.csv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error exporting {table}: {e}\")\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6icJVgVvaTbf",
        "outputId": "a517e728-2c36-49c1-a848-1ef40c03c76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported Categories to Categories.csv\n",
            "Exported sqlite_sequence to sqlite_sequence.csv\n",
            "Exported CustomerCustomerDemo to CustomerCustomerDemo.csv\n",
            "Exported CustomerDemographics to CustomerDemographics.csv\n",
            "Exported Customers to Customers.csv\n",
            "Exported Employees to Employees.csv\n",
            "Exported EmployeeTerritories to EmployeeTerritories.csv\n",
            "Exported Order Details to Order Details.csv\n",
            "Exported Orders to Orders.csv\n",
            "Exported Products to Products.csv\n",
            "Exported Regions to Regions.csv\n",
            "Exported Shippers to Shippers.csv\n",
            "Exported Suppliers to Suppliers.csv\n",
            "Exported Territories to Territories.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "storage_client = storage.Client(project=project_id)\n",
        "bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "# List of all your CSV files\n",
        "csv_files = ['Categories.csv', 'sqlite_sequence.csv', 'CustomerCustomerDemo.csv',\n",
        "             'CustomerDemographics.csv', 'Customers.csv', 'Employees.csv',\n",
        "             'EmployeeTerritories.csv', 'Order Details.csv', 'Orders.csv',\n",
        "             'Products.csv', 'Regions.csv', 'Shippers.csv',\n",
        "             'Suppliers.csv', 'Territories.csv']\n",
        "\n",
        "# Upload each CSV file to your GCS bucket\n",
        "for csv_file in csv_files:\n",
        "    blob = bucket.blob(csv_file)\n",
        "    blob.upload_from_filename(csv_file)  # Assuming the CSV files are in the current working directory\n",
        "    print(f\"Uploaded {csv_file} to GCS bucket {bucket_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61cuLVVbaUMl",
        "outputId": "4aa2958e-5bdc-4718-bc9f-3a952cb2b996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded Categories.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded sqlite_sequence.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded CustomerCustomerDemo.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded CustomerDemographics.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Customers.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Employees.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded EmployeeTerritories.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Order Details.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Orders.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Products.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Regions.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Shippers.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Suppliers.csv to GCS bucket northwind_dataset_bucket\n",
            "Uploaded Territories.csv to GCS bucket northwind_dataset_bucket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "# Initialize BigQuery client with your project ID\n",
        "project_id = 'text-sql-project'\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Specify the dataset where you want to load your tables\n",
        "dataset_id = 'northwind_dataset'  # Replace with your BigQuery dataset name\n",
        "\n",
        "# List of your CSV files in GCS\n",
        "csv_files = ['Categories.csv', 'sqlite_sequence.csv', 'CustomerCustomerDemo.csv',\n",
        "             'CustomerDemographics.csv', 'Customers.csv', 'Employees.csv',\n",
        "             'EmployeeTerritories.csv', 'Order Details.csv', 'Orders.csv',\n",
        "             'Products.csv', 'Regions.csv', 'Shippers.csv',\n",
        "             'Suppliers.csv', 'Territories.csv']\n",
        "\n",
        "# Name of your GCS bucket\n",
        "bucket_name = 'northwind_dataset_bucket'\n",
        "\n",
        "# Loop through each CSV file and load it into BigQuery\n",
        "for csv_file in csv_files:\n",
        "    # Replace space with underscores in table names\n",
        "    table_id = csv_file.replace('.csv', '').replace(' ', '_')  # Table name derived from CSV file\n",
        "\n",
        "    # Specify the URI of the CSV file in GCS\n",
        "    gcs_uri = f'gs://{bucket_name}/{csv_file}'\n",
        "\n",
        "    # Configure the load job\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        source_format=bigquery.SourceFormat.CSV,\n",
        "        skip_leading_rows=1,  # Skip header row\n",
        "        autodetect=True,  # Automatically detect schema based on CSV content\n",
        "        max_bad_records=10,  # Allow BigQuery to skip up to 5 bad records\n",
        "        quote_character='\"'  # Handle quoted strings properly\n",
        "    )\n",
        "\n",
        "    # Start the load job\n",
        "    load_job = client.load_table_from_uri(\n",
        "        gcs_uri,\n",
        "        f'{dataset_id}.{table_id}',  # BigQuery table name (same as CSV but without \".csv\")\n",
        "        job_config=job_config\n",
        "    )\n",
        "\n",
        "    # Wait for the job to complete\n",
        "    load_job.result()\n",
        "\n",
        "    print(f\"Loaded {table_id} into BigQuery.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcxK06_PhoWK",
        "outputId": "fbce6937-2fa1-41da-eb20-1a88a706bb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Categories into BigQuery.\n",
            "Loaded sqlite_sequence into BigQuery.\n",
            "Loaded CustomerCustomerDemo into BigQuery.\n",
            "Loaded CustomerDemographics into BigQuery.\n",
            "Loaded Customers into BigQuery.\n",
            "Loaded Employees into BigQuery.\n",
            "Loaded EmployeeTerritories into BigQuery.\n",
            "Loaded Order_Details into BigQuery.\n",
            "Loaded Orders into BigQuery.\n",
            "Loaded Products into BigQuery.\n",
            "Loaded Regions into BigQuery.\n",
            "Loaded Shippers into BigQuery.\n",
            "Loaded Suppliers into BigQuery.\n",
            "Loaded Territories into BigQuery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-_kXRIPhu57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}